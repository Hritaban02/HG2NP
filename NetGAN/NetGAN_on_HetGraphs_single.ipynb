{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Code.training import Trainer\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "from Code.utils import graph_from_scores, plot_scores\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "__HOME_DIR__ = \"/home/du4/19CS30053/MTP2\"\n",
    "__MAX_NODES__ = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(f\"{__HOME_DIR__}/Model/src/\")\n",
    "from lib import *\n",
    "from dataset import Heterogeneous_Graph_Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = input(\"Enter the dataset name:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_criteria = input(\"Enter the split criteria:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_criteria = (split_criteria).split(',') \n",
    "if len(split_criteria)==1:\n",
    "    split_criteria=split_criteria[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_title = dataset_name\n",
    "if isinstance(split_criteria, str):\n",
    "    dataset_title+=\"_\"\n",
    "    dataset_title+=split_criteria\n",
    "if isinstance(split_criteria, list):\n",
    "    dataset_title+=\"_\"\n",
    "    for s in split_criteria:\n",
    "        dataset_title+=\"_\"\n",
    "        dataset_title+=s\n",
    "\n",
    "dataset_title = \"single_\" + dataset_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Heterogeneous_Graph_Dataset(dataset_name=dataset_name, split_criteria=split_criteria)\n",
    "dataset.get_categorical_graph(on_split_data=True)\n",
    "\n",
    "# All homogeneous graphs\n",
    "real_data_list = dataset.split_data_category_graph\n",
    "\n",
    "new_real_data_list = []\n",
    "index_of_graph_with_max_nodes = -1\n",
    "num_max_nodes = 0\n",
    "for i, g in enumerate(real_data_list):\n",
    "    g.edge_index = g.edge_index.long()\n",
    "    if (index_of_graph_with_max_nodes==-1 or g['x'].shape[0]>num_max_nodes) and g['x'].shape[0] <= __MAX_NODES__ :\n",
    "        index_of_graph_with_max_nodes=i\n",
    "        num_max_nodes = g['x'].shape[0]\n",
    "new_real_data_list.append(real_data_list[index_of_graph_with_max_nodes])\n",
    "\n",
    "real_loader = DataLoader(new_real_data_list, batch_size=1024, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_every = 500\n",
    "plot_every = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for real in tqdm(real_loader):\n",
    "    adj = (to_dense_adj(real.edge_index, max_num_nodes=real.num_nodes)[0]>0.0).float().cpu().detach().numpy()\n",
    "    graph_sparse = scipy.sparse.csr_matrix(adj)\n",
    "\n",
    "    trainer = Trainer(graph_sparse, len(adj), max_iterations=20000, rw_len=12, batch_size=128, H_gen=40, H_disc=30, H_inp=128, z_dim=16, lr=0.0003,\n",
    "                  n_critic=3, gp_weight=10.0, betas=(.5, .9), l2_penalty_disc=5e-5, l2_penalty_gen=1e-7, temp_start=5.0,  \n",
    "                  val_share=0.2, test_share=0.1, seed=20, set_ops=False)\n",
    "    \n",
    "    trainer.train(create_graph_every=create_every, plot_graph_every=plot_every, num_samples_graph=50000, stopping_criterion='val', folder=f'{dataset_title}/actor_critic_plots')\n",
    "\n",
    "    plot_scores(trainer, create_every, filepath=f'{dataset_title}/score.png')\n",
    "\n",
    "    # save model\n",
    "    torch.save(trainer, f'{dataset_title}/Trainer.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NetGAN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
